{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-21T04:07:08.630192900Z",
     "start_time": "2024-02-21T04:07:08.190036800Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_list = []\n",
    "\n",
    "with open(\"csv/Pumpkin_Seeds_Dataset.csv\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    \n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        data_list.append(row)\n",
    "\n",
    "data = np.array(data_list)\n",
    "\n",
    "features = data[:, :-1].astype(float)\n",
    "labels = data[:, -1]\n",
    "labels = [0 if label[-1] == 'k' else 1 for label in labels]\n",
    "\n",
    "# normalisation\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "all_ids = np.arange(0, data.shape[0])\n",
    "random_seed = 1\n",
    "# training : test = 2000 : 500, real_training : validation = 1600 : 400 \n",
    "rem_set_ids, test_set_ids = train_test_split(all_ids, test_size=0.2, train_size=0.8,\n",
    "                                 random_state=random_seed, shuffle=True)\n",
    "train_set_ids, val_set_ids = train_test_split(rem_set_ids, test_size=0.2, train_size=0.8,\n",
    "                                 random_state=random_seed, shuffle=True)\n",
    "\n",
    "training_features = features[train_set_ids, :]\n",
    "training_labels = [labels[i] for i in train_set_ids]\n",
    "\n",
    "test_features = features[test_set_ids, :]\n",
    "test_labels = [labels[i] for i in test_set_ids]\n",
    "\n",
    "val_features = features[val_set_ids, :]\n",
    "val_labels = [labels[i] for i in val_set_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                self.hidden_layers.append(nn.Linear(input_size, hidden_sizes[i]))\n",
    "            else:\n",
    "                self.hidden_layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = torch.relu(hidden_layer(x))\n",
    "        output = self.output_layer(x)\n",
    "        return output\n",
    "\n",
    "# transfer the numpy data type to torch tensor type\n",
    "class MetDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx, :], self.labels[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:19:22.798575800Z",
     "start_time": "2024-02-21T19:19:22.794064400Z"
    }
   },
   "id": "508cd0d8345a9a6f"
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "features_count = training_features.shape[1]\n",
    "\n",
    "# Setting hyperparameters\n",
    "p_layers = [10, 20, 30]\n",
    "num_epochs = 20\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "# input_matrix(batch_size, features_count), output_matrix(hidden_size[-1], output_size)\n",
    "batch_sizes = [16, 32, 64]\n",
    "\n",
    "parameters = []\n",
    "for batch_size in batch_sizes:\n",
    "    for rate in learning_rates:\n",
    "        for p_layer in p_layers:\n",
    "            x = (p_layer, rate, batch_size)\n",
    "            parameters.append(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:19:24.818980800Z",
     "start_time": "2024-02-21T19:19:24.816203600Z"
    }
   },
   "id": "bfdd3cb855682ff8"
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "def calculate_accuracy(parameter):\n",
    "    \n",
    "    p_layer, rate, batch_size = parameter\n",
    "    \n",
    "    hidden_size = [p_layer, features_count]\n",
    "    output_size = np.unique(training_labels).shape[0]\n",
    "    \n",
    "    three_layer_MLP = FNN(features_count, hidden_size, output_size)\n",
    "    \n",
    "    # loading data by batch\n",
    "    train_set = MetDataset(training_features, training_labels)\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size)\n",
    "    \n",
    "    val_set = MetDataset(val_features, val_labels)\n",
    "    val_dataloader = DataLoader(val_set, batch_size=len(val_set))\n",
    "    \n",
    "    # Setting up the stochastic gradient descent optimizer for updating the model weights\n",
    "    optimizer = optim.SGD(three_layer_MLP.parameters(), lr=rate)\n",
    "    \n",
    "    # optimizer = optim.SGD(three_layer_MLP.parameters(), lr=learning_rate)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        three_layer_MLP.train()\n",
    "        \n",
    "        for batch, (x_train, y_train) in enumerate(train_dataloader):\n",
    "            # The gradient of the parameter is zeroed. In PyTorch, gradients are cumulative.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_pred = three_layer_MLP.forward(x_train)\n",
    "            train_loss = loss_function(train_pred, y_train)\n",
    "            \n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            # Evaluating on the validation set\n",
    "            val_accuracies = []\n",
    "            three_layer_MLP.eval()\n",
    "            for batch, (x_val, y_val) in enumerate(val_dataloader):\n",
    "                val_pred = three_layer_MLP.forward(x_val)\n",
    "                val_loss = loss_function(val_pred, y_val)\n",
    "                val_f1_scores, val_accuracy = my_metrics(y_val, val_pred)\n",
    "                val_accuracies.append(val_accuracy)\n",
    "\n",
    "            avg_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "\n",
    "    return avg_val_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:19:26.599402100Z",
     "start_time": "2024-02-21T19:19:26.593009500Z"
    }
   },
   "id": "36fa5ddac4569836"
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((20, 0.1, 16), 0.8625), ((30, 0.1, 64), 0.85), ((20, 0.01, 16), 0.8475), ((10, 0.1, 16), 0.8475), ((20, 0.1, 64), 0.8475), ((30, 0.01, 32), 0.845), ((30, 0.1, 32), 0.845), ((30, 0.01, 16), 0.8425), ((10, 0.1, 32), 0.8425), ((10, 0.01, 16), 0.84), ((20, 0.1, 32), 0.84), ((10, 0.1, 64), 0.8375), ((30, 0.1, 16), 0.8275), ((20, 0.01, 32), 0.81), ((10, 0.01, 32), 0.7025), ((10, 0.001, 16), 0.59), ((30, 0.001, 16), 0.5825), ((30, 0.001, 32), 0.5725), ((20, 0.001, 64), 0.5675), ((30, 0.001, 64), 0.5625), ((10, 0.01, 64), 0.5625), ((10, 0.001, 32), 0.555), ((20, 0.001, 16), 0.5525), ((20, 0.01, 64), 0.5525), ((30, 0.01, 64), 0.5525), ((10, 0.001, 64), 0.51), ((20, 0.001, 32), 0.4475)]\n",
      "\n",
      " ((20, 0.1, 16), 0.8625)\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for parameter in parameters:\n",
    "    accuracies.append((parameter, calculate_accuracy(parameter)))\n",
    "accuracies_sorted = sorted(accuracies, key=lambda x : x[1], reverse=True)\n",
    "print(accuracies_sorted)\n",
    "print('\\n', accuracies_sorted[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:22:12.471462600Z",
     "start_time": "2024-02-21T19:19:30.538908800Z"
    }
   },
   "id": "c47b3c50ace75ce8"
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    }
   ],
   "source": [
    "best_parameter = accuracies_sorted[0][0]\n",
    "\n",
    "calculate_accuracy(best_parameter)\n",
    "test_set = MetDataset(test_features, test_labels)\n",
    "test_dataloader = DataLoader(test_set, batch_size=len(test_set))\n",
    "test_accuracies = []\n",
    "three_layer_MLP.eval()\n",
    "for batch, (x_test, y_test) in enumerate(test_dataloader):\n",
    "    test_pred = three_layer_MLP.forward(x_test)\n",
    "    test_loss = loss_function(test_pred, y_test)\n",
    "    test_f1_scores, test_accuracy = my_metrics(y_test, test_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "print(avg_test_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:22:45.697767Z",
     "start_time": "2024-02-21T19:22:35.722219500Z"
    }
   },
   "id": "a8d830b059749362"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
